{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting ultralytics==8.3.240\n",
      "  Downloading ultralytics-8.3.240-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.240) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.240) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.240) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.240) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.240) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.240) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.240) (1.16.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.240) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.240) (0.24.0+cu126)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.240) (5.9.5)\n",
      "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.240) (1.31.0)\n",
      "Collecting ultralytics-thop>=2.0.18 (from ultralytics==8.3.240)\n",
      "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.11.12)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting pi-heif<2 (from roboflow)\n",
      "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting pillow-avif-plugin<2 (from roboflow)\n",
      "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
      "Collecting filetype (from roboflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.240) (1.3.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.240) (4.61.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.240) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.240) (3.2.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.3.240) (3.4.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.240) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics==8.3.240) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.3.240) (3.0.3)\n",
      "Downloading ultralytics-8.3.240-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, ultralytics-thop, roboflow, ultralytics\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.12.0.88\n",
      "    Uninstalling opencv-python-headless-4.12.0.88:\n",
      "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.11\n",
      "    Uninstalling idna-3.11:\n",
      "      Successfully uninstalled idna-3.11\n",
      "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11 ultralytics-8.3.240 ultralytics-thop-2.0.18\n"
     ]
    }
   ],
   "source": [
    "# Install specific versions to avoid compatibility issues\n",
    "!pip install roboflow ultralytics==8.3.240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "from glob import glob\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------------------------------------\n",
    "API_KEY = \"u0leKBS1HrAOJli1hvLI\"  # Provided by user\n",
    "\n",
    "# MAPPING CONFIGURATION\n",
    "# (Workspace, Project, Version, Target_Class_ID, Target_Class_Name, Oversample_Factor)\n",
    "dataset_config = [\n",
    "    # GLOBAL CLASS 0: Wagon (Factor=1)\n",
    "    (\"aispry-ob85t\", \"wagon-detection-zsnyn\", 2, 0, \"Wagon\", 1),\n",
    "    (\"alisha-nyb7f\", \"wagon-detection-qxlxh\", 1, 0, \"Wagon\", 1),\n",
    "    (\"wagons-thdfd\", \"cv-alt\", 2, 0, \"Wagon\", 1),\n",
    "    \n",
    "    # GLOBAL CLASS 1: Wagon parts (Factor=2)\n",
    "    (\"db-rail\", \"train-wagon-cv-project\", 3, 1, \"Wagon parts\", 2),\n",
    "    \n",
    "    # GLOBAL CLASS 2: Wagon numbers (Factor=25 - MASSIVE BOOST)\n",
    "    (\"sedykh-marat-dxrw3\", \"wagon-numbers-detection\", 1, 2, \"Wagon numbers\", 25),\n",
    "    (\"student-ih3dc\", \"wagon-detection-qc7bh\", 1, 2, \"Wagon numbers\", 25),\n",
    "    (\"wagoncounting\", \"wagon-numbers-jafet\", 1, 2, \"Wagon numbers\", 25),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_and_copy(source_path, dest_path_images, dest_path_labels, target_class_id, oversample_factor=1):\n",
    "    \"\"\"\n",
    "    Copies images and creates remapped label files.\n",
    "    Supports Oversampling: Copies files multiple times with unique names.\n",
    "    \"\"\"\n",
    "    os.makedirs(dest_path_images, exist_ok=True)\n",
    "    os.makedirs(dest_path_labels, exist_ok=True)\n",
    "\n",
    "    # We look for images in the source\n",
    "    source_images = glob(os.path.join(source_path, 'images', '*'))\n",
    "    \n",
    "    for img_path in source_images:\n",
    "        basename = os.path.basename(img_path)\n",
    "        name_root, ext = os.path.splitext(basename)\n",
    "        \n",
    "        # Check for Label existence first\n",
    "        src_label_file = os.path.join(source_path, 'labels', f\"{name_root}.txt\")\n",
    "        if not os.path.exists(src_label_file):\n",
    "            continue\n",
    "\n",
    "        # Prepare Label Content\n",
    "        with open(src_label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        new_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                # Replace original class_id with target_class_id\n",
    "                new_line = f\"{target_class_id} \" + \" \".join(parts[1:])\n",
    "                new_lines.append(new_line)\n",
    "        \n",
    "        if not new_lines: continue\n",
    "        \n",
    "        # --- OVERSAMPLING LOOP ---\n",
    "        for i in range(oversample_factor):\n",
    "            # Unique suffix for duplicates\n",
    "            suffix = f\"_copy{i}\" if i > 0 else \"\"\n",
    "            new_name_root = f\"{name_root}{suffix}\"\n",
    "            \n",
    "            # Copy Image\n",
    "            dest_img_path = os.path.join(dest_path_images, f\"{new_name_root}{ext}\")\n",
    "            shutil.copy(img_path, dest_img_path)\n",
    "            \n",
    "            # Write Label\n",
    "            dest_label_path = os.path.join(dest_path_labels, f\"{new_name_root}.txt\")\n",
    "            with open(dest_label_path, 'w') as f:\n",
    "                f.write('\\n'.join(new_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "STEP 1: Downloading & Merging Datasets (With Balancing)\n",
      "------------------------------------------------------------\n",
      "Processing aispry-ob85t/wagon-detection-zsnyn v2 -> Class 0 (x1)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Wagon-detection-2 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 156603/156603 [00:02<00:00, 69622.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Wagon-detection-2 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4454/4454 [00:00<00:00, 6408.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alisha-nyb7f/wagon-detection-qxlxh v1 -> Class 0 (x1)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in wagon-detection-1 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1715/1715 [00:00<00:00, 7595.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to wagon-detection-1 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [00:00<00:00, 7071.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing wagons-thdfd/cv-alt v2 -> Class 0 (x1)\n",
      "loading Roboflow workspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in CV-alt-2 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40144/40144 [00:00<00:00, 50735.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to CV-alt-2 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 766/766 [00:00<00:00, 6036.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing db-rail/train-wagon-cv-project v3 -> Class 1 (x2)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Train-Wagon-CV-Project-3 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128815/128815 [00:01<00:00, 69846.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Train-Wagon-CV-Project-3 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5442/5442 [00:00<00:00, 7639.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sedykh-marat-dxrw3/wagon-numbers-detection v1 -> Class 2 (x25)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Wagon-numbers-detection-1 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12948/12948 [00:00<00:00, 25865.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Wagon-numbers-detection-1 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 376/376 [00:00<00:00, 7788.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student-ih3dc/wagon-detection-qc7bh v1 -> Class 2 (x25)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Processing wagoncounting/wagon-numbers-jafet v1 -> Class 2 (x25)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Wagon-numbers-1 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38165/38165 [00:01<00:00, 36793.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Wagon-numbers-1 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:00<00:00, 3019.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preparation Complete!\n"
     ]
    }
   ],
   "source": [
    "rf = Roboflow(api_key=API_KEY)\n",
    "    \n",
    "# Create Merged Dataset Structure\n",
    "MERGED_DIR = \"railway_hackathon_merged_oversampled\"\n",
    "if os.path.exists(MERGED_DIR): shutil.rmtree(MERGED_DIR) \n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    os.makedirs(os.path.join(MERGED_DIR, split, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(MERGED_DIR, split, 'labels'), exist_ok=True)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"STEP 1: Downloading & Merging Datasets (With Balancing)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for workspace, project_id, version, target_id, target_name, factor in dataset_config:\n",
    "    try:\n",
    "        print(f\"Processing {workspace}/{project_id} v{version} -> Class {target_id} (x{factor})\")\n",
    "        project = rf.workspace(workspace).project(project_id)\n",
    "        dataset = project.version(version).download(\"yolov8\")\n",
    "        \n",
    "        location = dataset.location\n",
    "        \n",
    "        # Merge Train, Valid, Test splits\n",
    "        for split in ['train', 'valid', 'test']:\n",
    "            src_split_path = os.path.join(location, split)\n",
    "            if not os.path.exists(src_split_path): \n",
    "                continue\n",
    "                \n",
    "            dest_images = os.path.join(MERGED_DIR, split, 'images')\n",
    "            dest_labels = os.path.join(MERGED_DIR, split, 'labels')\n",
    "            \n",
    "            remap_and_copy(src_split_path, dest_images, dest_labels, target_id, factor)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {project_id}: {e}\")\n",
    "\n",
    "# Create Custom data.yaml\n",
    "yaml_content = {\n",
    "    'train': os.path.abspath(os.path.join(MERGED_DIR, 'train', 'images')),\n",
    "    'val': os.path.abspath(os.path.join(MERGED_DIR, 'valid', 'images')),\n",
    "    'test': os.path.abspath(os.path.join(MERGED_DIR, 'test', 'images')),\n",
    "    'nc': 3,\n",
    "    'names': ['Wagon', 'Wagon parts', 'Wagon numbers']\n",
    "}\n",
    "\n",
    "yaml_path = os.path.join(MERGED_DIR, 'data.yaml')\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(yaml_content, f)\n",
    "\n",
    "print(\"Dataset Preparation Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.240 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=railway_hackathon_merged_oversampled/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=5, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=merged_model_v44, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=railway_hackathon_take5, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/railway_hackathon_take5/merged_model_v44, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117209  ultralytics.nn.modules.head.Detect           [3, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,136,761 parameters, 11,136,745 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1502.0¬±772.9 MB/s, size: 62.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/railway_hackathon_merged_oversampled/train/labels.cache... 15017 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 15017/15017 21.5Mit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 6413, len(boxes) = 25344. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (23.7GB Disk): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 15017/15017 65.1it/s 3:511<0.1s\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 314.4¬±475.4 MB/s, size: 54.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/railway_hackathon_merged_oversampled/valid/labels.cache... 1651 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1651/1651 2.1Mit/s 0.0ss\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 1035, len(boxes) = 2460. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (1.5GB Disk): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1651/1651 75.9it/s 21.8s<0.1s\n",
      "Plotting labels to /content/railway_hackathon_take5/merged_model_v44/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/content/railway_hackathon_take5/merged_model_v44\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      7.44G       1.31      1.822      1.346        135        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 4:58<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.5s/it 19.2s1.1s\n",
      "                   all       1651       2460      0.879      0.814      0.852      0.654\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      7.72G     0.9492     0.7846      1.071        114        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 4:56<0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 15.8s1.4s\n",
      "                   all       1651       2460      0.893      0.822      0.891      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      7.19G     0.9762     0.8005      1.084        101        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 4:55<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 15.5s1.4s\n",
      "                   all       1651       2460      0.887      0.738      0.828      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      7.22G     0.9875     0.8025      1.093        114        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 4:59<0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 15.1s1.4s\n",
      "                   all       1651       2460      0.841      0.841      0.878      0.662\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50       7.2G     0.9165     0.7198      1.065        121        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 4:54<0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 16.0s1.3s\n",
      "                   all       1651       2460      0.915      0.822      0.892      0.689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      7.23G     0.8645     0.6713      1.045        117        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 4:58<0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 15.7s1.2s\n",
      "                   all       1651       2460      0.898       0.86      0.909      0.689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      7.14G     0.8253     0.6344      1.032        100        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 4:56<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 15.5s1.3s\n",
      "                   all       1651       2460      0.883      0.857      0.904      0.714\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      7.33G     0.7937      0.612      1.017        117        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:01<0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 16.1s1.4s\n",
      "                   all       1651       2460      0.923       0.85      0.907      0.728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      7.28G     0.7654     0.5856      1.004        109        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:02<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 15.6s1.3s\n",
      "                   all       1651       2460      0.954      0.843      0.926      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      7.15G     0.7395      0.557      0.993         81        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:10<1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.8s1.2s\n",
      "                   all       1651       2460      0.904      0.863      0.918      0.743\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      7.19G     0.7237     0.5444     0.9856        140        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:15<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.9s1.3s\n",
      "                   all       1651       2460      0.928      0.854      0.923      0.745\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      7.24G     0.7126     0.5352     0.9839        115        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:13<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.3s1.3s\n",
      "                   all       1651       2460      0.931       0.84       0.92      0.755\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      7.15G     0.6948     0.5161     0.9767        128        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:14<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.3s1.2s\n",
      "                   all       1651       2460      0.903      0.872      0.927      0.773\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      7.22G     0.6822      0.507     0.9737        128        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:10<0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.4s1.2s\n",
      "                   all       1651       2460       0.92      0.884      0.926      0.769\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50      7.53G     0.6693      0.497     0.9662        127        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:15<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.0s1.2s\n",
      "                   all       1651       2460      0.909      0.884      0.923      0.768\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50       7.3G       0.65     0.4835     0.9578        115        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:13<1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.9s1.4s\n",
      "                   all       1651       2460      0.932      0.884       0.93      0.777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50      7.36G      0.644     0.4772     0.9558        119        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:16<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 15.4s1.3s\n",
      "                   all       1651       2460      0.922      0.878      0.921      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      7.33G     0.6325      0.468     0.9529        140        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:12<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 15.0s1.3s\n",
      "                   all       1651       2460       0.94      0.879      0.937       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      7.22G     0.6243     0.4575     0.9508        119        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:10<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.3s/it 16.4s1.4s\n",
      "                   all       1651       2460      0.929      0.875       0.93      0.774\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      7.21G     0.6165     0.4544     0.9449        114        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:12<1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 15.1s1.5s\n",
      "                   all       1651       2460      0.954      0.868      0.934      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50      7.22G     0.6047     0.4402     0.9409        122        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:11<1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.9s1.4s\n",
      "                   all       1651       2460      0.947      0.875      0.935      0.795\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50      7.14G     0.5972     0.4361     0.9382        116        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:12<0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.5s1.3s\n",
      "                   all       1651       2460      0.933      0.869      0.935      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50      7.18G     0.5851     0.4243     0.9316        114        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:14<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.5s1.3s\n",
      "                   all       1651       2460      0.954      0.864      0.932      0.787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      7.14G     0.5755     0.4183      0.931        116        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:14<0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.1s1.3s\n",
      "                   all       1651       2460       0.94      0.874      0.928      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50      7.15G     0.5665     0.4137      0.926        137        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:14<1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.4s1.3s\n",
      "                   all       1651       2460      0.928      0.869      0.931      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      7.24G     0.5599     0.4045     0.9246         91        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:15<0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 15.2s1.2s\n",
      "                   all       1651       2460      0.932       0.88      0.928      0.786\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50      7.21G     0.5544     0.4005     0.9233        112        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:13<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 15.9s1.4s\n",
      "                   all       1651       2460       0.93      0.874      0.933      0.791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50       7.3G     0.5388      0.389      0.918        136        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:15<0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.9s1.3s\n",
      "                   all       1651       2460      0.934      0.876      0.929      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50      7.32G     0.5359     0.3857       0.92        132        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:16<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.5s1.2s\n",
      "                   all       1651       2460      0.926      0.871      0.926      0.784\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50      7.12G     0.5236     0.3742     0.9122        120        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:15<0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.8s1.3s\n",
      "                   all       1651       2460      0.929      0.876      0.925      0.787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50      7.31G     0.5147     0.3684     0.9089        109        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 235/235 1.3s/it 5:16<0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.1s/it 14.4s1.3s\n",
      "                   all       1651       2460      0.938      0.865      0.926      0.788\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 21, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "31 epochs completed in 2.807 hours.\n",
      "Optimizer stripped from /content/railway_hackathon_take5/merged_model_v44/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from /content/railway_hackathon_take5/merged_model_v44/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating /content/railway_hackathon_take5/merged_model_v44/weights/best.pt...\n",
      "Ultralytics 8.3.240 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 72 layers, 11,126,745 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 1.2s/it 16.2s1.2s\n",
      "                   all       1651       2460      0.948      0.875      0.935      0.795\n",
      "                 Wagon        216        721      0.931      0.728      0.873      0.654\n",
      "           Wagon parts        560        864      0.917      0.926      0.952      0.894\n",
      "         Wagon numbers        875        875      0.995      0.971      0.981      0.836\n",
      "Speed: 0.1ms preprocess, 3.6ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1m/content/railway_hackathon_take5/merged_model_v44\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model = YOLO('yolov8s.pt') \n",
    "\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=64,\n",
    "    project='railway_hackathon_take5',\n",
    "    name='merged_model_v4',\n",
    "    freeze=5,\n",
    "    lr0=0.001,\n",
    "    patience=10,\n",
    "    workers=8,\n",
    "    cache='disk',\n",
    "    cos_lr=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Path based on your logs\n",
    "weights_path = '/content/railway_hackathon_take5/merged_model_v4/weights/best.pt'\n",
    "results_folder = '/content/railway_hackathon_take5/merged_model_v4'\n",
    "\n",
    "if os.path.exists(weights_path):\n",
    "    print(f\"‚úÖ Model found at: {weights_path}\")\n",
    "    \n",
    "    # Option 1: Download just the weights (faster)\n",
    "    print(\"Downloading best.pt...\")\n",
    "    files.download(weights_path)\n",
    "    \n",
    "    # Option 2: Zip the full results (logs, graphs, weights) and download\n",
    "    print(\"Zipping full results folder...\")\n",
    "    shutil.make_archive('training_results', 'zip', results_folder)\n",
    "    files.download('training_results.zip')\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå File not found. If the Runtime completely disconnected/reset, the files might be lost.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "source_folder = '/content/railway_hackathon_take5'  # Change if your model folder has a different name/path\n",
    "\n",
    "if not os.path.exists(source_folder):\n",
    "    print(f\"‚ùå Folder not found: {source_folder}\")\n",
    "    print(\"   Check the exact path with !ls /content/\")\n",
    "else:\n",
    "    print(f\"üìÅ Found folder: {source_folder}\")\n",
    "    print(\"üì¶ Zipping the folder...\")\n",
    "    \n",
    "    zip_path = '/content/railway_hackathon_results.zip'\n",
    "    \n",
    "    # Use system zip for speed and reliability\n",
    "    !zip -r {zip_path} {source_folder}\n",
    "    \n",
    "    if os.path.exists(zip_path):\n",
    "        size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n",
    "        print(f\"‚úÖ Zip created: {zip_path} ({size_mb:.1f} MB)\")\n",
    "        print(\"‚¨áÔ∏è Starting automatic download to your computer...\")\n",
    "        files.download(zip_path)  # This triggers a direct browser download\n",
    "    else:\n",
    "        print(\"‚ùå Zip creation failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-auth-oauthlib  # One-time if needed\n",
    "\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "service = build('drive', 'v3')\n",
    "\n",
    "# Manual mount simulation\n",
    "mount_point = '/content/drive'\n",
    "if not os.path.exists(mount_point):\n",
    "    os.makedirs(mount_point)\n",
    "\n",
    "# Copy your files/zip to a temp spot first (if not already zipped)\n",
    "source_zip = '/content/railway_hackathon_results.zip'  # Or recreate: !zip -r {source_zip} /content/railway_hackathon_take4\n",
    "\n",
    "# Upload to Drive root (or change folder_id for a subfolder)\n",
    "file_metadata = {'name': 'railway_hackathon_results.zip'}\n",
    "media = MediaFileUpload(source_zip, resumable=True)\n",
    "uploaded_file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "\n",
    "print(f\"‚úÖ Uploaded to Drive! File ID: {uploaded_file.get('id')}\")\n",
    "print(\"Go to drive.google.com, search for 'railway_hackathon_results.zip', right-click ‚Üí Download.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
