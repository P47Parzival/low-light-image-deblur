{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d15c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.239)\n",
      "Requirement already satisfied: roboflow in /usr/local/lib/python3.12/dist-packages (1.2.11)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.11.12)\n",
      "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: pi-heif<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
      "Requirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f024514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed2d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_and_copy(source_path, dest_path_images, dest_path_labels, target_class_id):\n",
    "    \"\"\"\n",
    "    Copies images and creates remapped label files.\n",
    "    \"\"\"\n",
    "    os.makedirs(dest_path_images, exist_ok=True)\n",
    "    os.makedirs(dest_path_labels, exist_ok=True)\n",
    "\n",
    "    # Process images and corresponding labels\n",
    "    # YOLOv8 datasets usually have 'images' and 'labels' folders\n",
    "    \n",
    "    # We look for images in the source\n",
    "    source_images = glob(os.path.join(source_path, 'images', '*'))\n",
    "    \n",
    "    for img_path in source_images:\n",
    "        # Copy Image\n",
    "        shutil.copy(img_path, dest_path_images)\n",
    "        \n",
    "        # Process Label\n",
    "        basename = os.path.basename(img_path)\n",
    "        name_root, _ = os.path.splitext(basename)\n",
    "        label_file = os.path.join(source_path, 'labels', f\"{name_root}.txt\")\n",
    "        \n",
    "        if os.path.exists(label_file):\n",
    "            with open(label_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    # Replace original class_id with target_class_id\n",
    "                    # We keep coordinates/dimensions same\n",
    "                    new_line = f\"{target_class_id} \" + \" \".join(parts[1:])\n",
    "                    new_lines.append(new_line)\n",
    "            \n",
    "            if new_lines:\n",
    "                with open(os.path.join(dest_path_labels, f\"{name_root}.txt\"), 'w') as f:\n",
    "                    f.write('\\n'.join(new_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3e8178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"u0leKBS1HrAOJli1hvLI\"\n",
    "\n",
    "if api_key == \"YOUR_API_KEY\":\n",
    "    print(\"Please replace 'YOUR_API_KEY' within the script.\")\n",
    "\n",
    "# MAPPING CONFIGURATION\n",
    "# (Workspace, Project, Version, Target_Class_ID, Target_Class_Name)\n",
    "dataset_config = [\n",
    "    # GLOBAL CLASS 0: Wagon\n",
    "    (\"aispry-ob85t\", \"wagon-detection-zsnyn\", 2, 0, \"Wagon\"),\n",
    "    (\"alisha-nyb7f\", \"wagon-detection-qxlxh\", 1, 0, \"Wagon\"),\n",
    "    (\"wagons-thdfd\", \"cv-alt\", 2, 0, \"Wagon\"),\n",
    "    \n",
    "    # GLOBAL CLASS 1: Wagon parts\n",
    "    (\"db-rail\", \"train-wagon-cv-project\", 3, 1, \"Wagon parts\"),\n",
    "    \n",
    "    # GLOBAL CLASS 2: Wagon numbers\n",
    "    (\"sedykh-marat-dxrw3\", \"wagon-numbers-detection\", 1, 2, \"Wagon numbers\"),\n",
    "    (\"student-ih3dc\", \"wagon-detection-qc7bh\", 1, 2, \"Wagon numbers\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3fec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "STEP 1: Downloading & Merging Datasets\n",
      "------------------------------------------------------------\n",
      "Processing aispry-ob85t/wagon-detection-zsnyn v2 -> Class 0 (Wagon)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Wagon-detection-2 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156603/156603 [00:03<00:00, 51773.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Wagon-detection-2 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4454/4454 [00:00<00:00, 6075.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alisha-nyb7f/wagon-detection-qxlxh v1 -> Class 0 (Wagon)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in wagon-detection-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1715/1715 [00:00<00:00, 5916.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to wagon-detection-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:00<00:00, 3730.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing wagons-thdfd/cv-alt v2 -> Class 0 (Wagon)\n",
      "loading Roboflow workspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in CV-alt-2 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40144/40144 [00:00<00:00, 43646.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to CV-alt-2 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 766/766 [00:00<00:00, 5972.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing db-rail/train-wagon-cv-project v3 -> Class 1 (Wagon parts)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Train-Wagon-CV-Project-3 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128815/128815 [00:01<00:00, 65340.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Train-Wagon-CV-Project-3 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5442/5442 [00:00<00:00, 7484.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sedykh-marat-dxrw3/wagon-numbers-detection v1 -> Class 2 (Wagon numbers)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Wagon-numbers-detection-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12948/12948 [00:00<00:00, 30354.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Wagon-numbers-detection-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 376/376 [00:00<00:00, 5526.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing student-ih3dc/wagon-detection-qc7bh v1 -> Class 2 (Wagon numbers)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "rf = Roboflow(api_key=api_key)\n",
    "\n",
    "# Create Merged Dataset Structure\n",
    "MERGED_DIR = \"railway_hackathon_merged\"\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    os.makedirs(os.path.join(MERGED_DIR, split, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(MERGED_DIR, split, 'labels'), exist_ok=True)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"STEP 1: Downloading & Merging Datasets\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for workspace, project_id, version, target_id, target_name in dataset_config:\n",
    "    try:\n",
    "        print(f\"Processing {workspace}/{project_id} v{version} -> Class {target_id} ({target_name})\")\n",
    "        project = rf.workspace(workspace).project(project_id)\n",
    "        dataset = project.version(version).download(\"yolov8\")\n",
    "        \n",
    "        location = dataset.location\n",
    "        \n",
    "        # Merge Train, Valid, Test splits\n",
    "        for split in ['train', 'valid', 'test']:\n",
    "            # Some datasets might use 'train' or 'valid' folders differently, standardizing here\n",
    "            src_split_path = os.path.join(location, split)\n",
    "            if not os.path.exists(src_split_path): \n",
    "                # Try fallback if Roboflow structure varies\n",
    "                continue\n",
    "                \n",
    "            dest_images = os.path.join(MERGED_DIR, split, 'images')\n",
    "            dest_labels = os.path.join(MERGED_DIR, split, 'labels')\n",
    "            \n",
    "            remap_and_copy(src_split_path, dest_images, dest_labels, target_id)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {project_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4bb4fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Dataset Merged at: railway_hackathon_merged\n"
     ]
    }
   ],
   "source": [
    "# Create Custom data.yaml\n",
    "yaml_content = {\n",
    "    'train': os.path.abspath(os.path.join(MERGED_DIR, 'train', 'images')),\n",
    "    'val': os.path.abspath(os.path.join(MERGED_DIR, 'valid', 'images')),\n",
    "    'test': os.path.abspath(os.path.join(MERGED_DIR, 'test', 'images')),\n",
    "    'nc': 3,\n",
    "    'names': ['Wagon', 'Wagon parts', 'Wagon numbers']\n",
    "}\n",
    "\n",
    "yaml_path = os.path.join(MERGED_DIR, 'data.yaml')\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(yaml_content, f)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Dataset Merged at: {MERGED_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b5cd84",
   "metadata": {},
   "source": [
    "# Train YOLO Model\n",
    "Initialize the YOLO model (e.g., `yolov8n.pt`) and execute the training process using the generated `data.yaml` file with specified hyperparameters (epochs, batch size, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68d9e377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: Starting Training on Merged Dataset\n",
      "------------------------------------------------------------\n",
      "Ultralytics 8.3.239 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=railway_hackathon_merged/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=merged_model_v22, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=railway_hackathon_take3, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/railway_hackathon_take3/merged_model_v22, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117209  ultralytics.nn.modules.head.Detect           [3, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,136,761 parameters, 11,136,745 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1794.5Â±472.8 MB/s, size: 59.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/railway_hackathon_merged/train/labels.cache... 4011 images, 685 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4696/4696 7.1Mit/s 0.0s\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 4186, len(boxes) = 10447. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 1.37G reserved, 0.25G allocated, 13.13G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    11136761       28.65         1.128         17.82         12.32        (1, 3, 640, 640)                    list\n",
      "    11136761        57.3         1.143         17.87          16.7        (2, 3, 640, 640)                    list\n",
      "    11136761       114.6         1.200         29.17          25.5        (4, 3, 640, 640)                    list\n",
      "    11136761       229.2         1.617         52.26         39.66        (8, 3, 640, 640)                    list\n",
      "    11136761       458.4         2.345         91.81         64.73       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 83 for CUDA:0 9.59G/14.74G (65%) âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1794.4Â±464.8 MB/s, size: 63.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/railway_hackathon_merged/train/labels.cache... 4011 images, 685 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4696/4696 9.5Mit/s 0.0s\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 4186, len(boxes) = 10447. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 645.6Â±731.1 MB/s, size: 73.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/railway_hackathon_merged/valid/labels.cache... 501 images, 80 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 581/581 204.0Kit/s 0.0s\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 612, len(boxes) = 1158. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "Plotting labels to /content/railway_hackathon_take3/merged_model_v22/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0006484375), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/content/railway_hackathon_take3/merged_model_v22\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      7.35G      1.338      2.046      1.536        201        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.4s/it 1:201.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.9s/it 7.7s2.8ss\n",
      "                   all        581       1158      0.893      0.509      0.543       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      8.23G       1.06      1.026      1.277        219        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:080.8sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.9s/it 7.4s3.1ss\n",
      "                   all        581       1158      0.771      0.498       0.47      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      8.08G      1.053     0.9659      1.263        153        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:090.9sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.8s/it 7.3s3.0ss\n",
      "                   all        581       1158      0.811      0.489      0.511      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50       8.2G      1.031     0.9186      1.243        205        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:101.0sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.6s/it 6.6s2.7ss\n",
      "                   all        581       1158      0.903      0.483      0.547      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50      8.23G     0.9846     0.8457      1.212        219        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:100.9sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.7s/it 6.7s2.8ss\n",
      "                   all        581       1158      0.603      0.638       0.63      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      8.23G     0.9376     0.7928      1.181        235        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:090.9sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.8s/it 7.4s2.9ss\n",
      "                   all        581       1158      0.596      0.532       0.58      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      8.22G     0.9113     0.7788       1.17        227        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:090.8sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.1s/it 8.4s3.4ss\n",
      "                   all        581       1158      0.915      0.537       0.59       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         8G     0.9077      0.757       1.17        207        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:111.0sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.6s/it 6.5s2.8ss\n",
      "                   all        581       1158      0.923      0.546      0.587       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         8G     0.8751     0.7242      1.151        234        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.3s/it 1:111.0sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.6s/it 6.4s2.6ss\n",
      "                   all        581       1158      0.775      0.687      0.763      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      8.22G     0.8571     0.7043      1.143        226        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:100.8sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.9s/it 7.4s3.0ss\n",
      "                   all        581       1158        0.7      0.698      0.714      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50       8.2G     0.8563     0.6929      1.131        217        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:100.9sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.1s/it 8.2s3.1ss\n",
      "                   all        581       1158      0.667       0.84      0.688      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      7.89G     0.8408     0.6765      1.125        215        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:101.1s4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.6s/it 6.3s2.6ss\n",
      "                   all        581       1158       0.75      0.836      0.791      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      8.23G     0.8265      0.658      1.115        206        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:110.9sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.7s/it 6.7s2.7ss\n",
      "                   all        581       1158      0.746      0.818      0.806      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      8.22G     0.8257     0.6541      1.111        241        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:100.8sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.0s/it 8.0s3.3ss\n",
      "                   all        581       1158      0.604      0.708       0.69      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50       8.2G     0.8027     0.6312        1.1        174        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:090.9sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.7s/it 6.9s3.0ss\n",
      "                   all        581       1158      0.728      0.698      0.779      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      7.99G     0.8023     0.6255      1.096        196        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:101.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.7s/it 6.7s2.8ss\n",
      "                   all        581       1158      0.897       0.61      0.727      0.568\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50      8.23G     0.7963      0.614      1.095        223        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 57/57 1.2s/it 1:100.9s1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.8s/it 7.4s2.8ss\n",
      "                   all        581       1158      0.803      0.676      0.727      0.559\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 5 epochs. Best results observed at epoch 12, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "17 epochs completed in 0.376 hours.\n",
      "Optimizer stripped from /content/railway_hackathon_take3/merged_model_v22/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from /content/railway_hackathon_take3/merged_model_v22/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating /content/railway_hackathon_take3/merged_model_v22/weights/best.pt...\n",
      "Ultralytics 8.3.239 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 72 layers, 11,126,745 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.2s/it 8.6s3.4ss\n",
      "                   all        581       1158      0.752      0.836      0.791      0.606\n",
      "                 Wagon        216        721      0.799      0.784      0.848      0.619\n",
      "           Wagon parts        280        432      0.839      0.924       0.93      0.847\n",
      "         Wagon numbers          5          5      0.617        0.8      0.596       0.35\n",
      "Speed: 0.2ms preprocess, 4.1ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1m/content/railway_hackathon_take3/merged_model_v22\u001b[0m\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 2: Starting Training on Merged Dataset\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Train\n",
    "model = YOLO('yolov8s.pt') \n",
    "\n",
    "try:\n",
    "    results = model.train(\n",
    "        data=yaml_path,\n",
    "        epochs=50,\n",
    "        imgsz=640,\n",
    "        batch=-1,\n",
    "        project='railway_hackathon_take3',\n",
    "        name='merged_model_v2',\n",
    "        freeze=10,\n",
    "        lr0=0.001,\n",
    "        patience=5\n",
    "    )\n",
    "    print(\"Training Complete!\")\n",
    "except Exception as e:\n",
    "    print(f\"Training Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "755de485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model found at: /content/railway_hackathon_take3/merged_model_v2/weights/best.pt\n",
      "Downloading best.pt...\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_3aa390c3-9d79-4718-8ab5-46cea06e85e5\", \"best.pt\", 22513450)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping full results folder...\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_f8083e6e-ed13-467f-8e99-0ef033f5ea9b\", \"training_results.zip\", 47761286)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Path based on your logs\n",
    "weights_path = '/content/railway_hackathon_take3/merged_model_v2/weights/best.pt'\n",
    "results_folder = '/content/railway_hackathon_take3/merged_model_v2'\n",
    "\n",
    "if os.path.exists(weights_path):\n",
    "    print(f\"âœ… Model found at: {weights_path}\")\n",
    "    \n",
    "    # Option 1: Download just the weights (faster)\n",
    "    print(\"Downloading best.pt...\")\n",
    "    files.download(weights_path)\n",
    "    \n",
    "    # Option 2: Zip the full results (logs, graphs, weights) and download\n",
    "    print(\"Zipping full results folder...\")\n",
    "    shutil.make_archive('training_results', 'zip', results_folder)\n",
    "    files.download('training_results.zip')\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ File not found. If the Runtime completely disconnected/reset, the files might be lost.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cade8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Found folder: /content/railway_hackathon_take3\n",
      "ğŸ“¦ Zipping the folder...\n",
      "  adding: content/railway_hackathon_take3/ (stored 0%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/ (stored 0%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/BoxF1_curve.png (deflated 13%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/BoxP_curve.png (deflated 10%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/results.png (deflated 8%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/confusion_matrix.png (deflated 26%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/BoxPR_curve.png (deflated 12%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/val_batch1_pred.jpg (deflated 5%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/train_batch2.jpg (deflated 2%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/results.csv (deflated 51%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/labels.jpg (deflated 29%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/confusion_matrix_normalized.png (deflated 25%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/weights/ (stored 0%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/weights/best.pt (deflated 8%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/weights/last.pt (deflated 8%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/BoxR_curve.png (deflated 13%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/train_batch0.jpg (deflated 3%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/args.yaml (deflated 53%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/val_batch0_labels.jpg (deflated 6%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/train_batch1.jpg (deflated 3%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/val_batch1_labels.jpg (deflated 5%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/val_batch2_pred.jpg (deflated 15%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/val_batch0_pred.jpg (deflated 6%)\n",
      "  adding: content/railway_hackathon_take3/merged_model_v2/val_batch2_labels.jpg (deflated 16%)\n",
      "âœ… Zip created: /content/railway_hackathon_results.zip (45.5 MB)\n",
      "â¬‡ï¸ Starting automatic download to your computer...\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_560eaab1-6f4d-4d31-9b91-682d51ec87cc\", \"railway_hackathon_results.zip\", 47685356)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "source_folder = '/content/railway_hackathon_take3'  # Change if your model folder has a different name/path\n",
    "\n",
    "if not os.path.exists(source_folder):\n",
    "    print(f\"âŒ Folder not found: {source_folder}\")\n",
    "    print(\"   Check the exact path with !ls /content/\")\n",
    "else:\n",
    "    print(f\"ğŸ“ Found folder: {source_folder}\")\n",
    "    print(\"ğŸ“¦ Zipping the folder...\")\n",
    "    \n",
    "    zip_path = '/content/railway_hackathon_results.zip'\n",
    "    \n",
    "    # Use system zip for speed and reliability\n",
    "    !zip -r {zip_path} {source_folder}\n",
    "    \n",
    "    if os.path.exists(zip_path):\n",
    "        size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n",
    "        print(f\"âœ… Zip created: {zip_path} ({size_mb:.1f} MB)\")\n",
    "        print(\"â¬‡ï¸ Starting automatic download to your computer...\")\n",
    "        files.download(zip_path)  # This triggers a direct browser download\n",
    "    else:\n",
    "        print(\"âŒ Zip creation failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c17b273d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_f018a727-5ddc-4e96-9b94-fb0109238f01\", \"best.pt\", 22513450)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('/content/railway_hackathon_take3/merged_model_v2/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21e1ef20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/railway_hackathon_take3:\n",
      "merged_model_v2  merged_model_v22\n",
      "\n",
      "/content/railway_hackathon_take3/merged_model_v2:\n",
      "args.yaml\t\t\t labels.jpg\t\tval_batch0_pred.jpg\n",
      "BoxF1_curve.png\t\t\t results.csv\t\tval_batch1_labels.jpg\n",
      "BoxP_curve.png\t\t\t results.png\t\tval_batch1_pred.jpg\n",
      "BoxPR_curve.png\t\t\t train_batch0.jpg\tval_batch2_labels.jpg\n",
      "BoxR_curve.png\t\t\t train_batch1.jpg\tval_batch2_pred.jpg\n",
      "confusion_matrix_normalized.png  train_batch2.jpg\tweights\n",
      "confusion_matrix.png\t\t val_batch0_labels.jpg\n",
      "\n",
      "/content/railway_hackathon_take3/merged_model_v2/weights:\n",
      "best.pt  last.pt\n",
      "\n",
      "/content/railway_hackathon_take3/merged_model_v22:\n",
      "args.yaml\t\t\t labels.jpg\t\tval_batch0_pred.jpg\n",
      "BoxF1_curve.png\t\t\t results.csv\t\tval_batch1_labels.jpg\n",
      "BoxP_curve.png\t\t\t results.png\t\tval_batch1_pred.jpg\n",
      "BoxPR_curve.png\t\t\t train_batch0.jpg\tval_batch2_labels.jpg\n",
      "BoxR_curve.png\t\t\t train_batch1.jpg\tval_batch2_pred.jpg\n",
      "confusion_matrix_normalized.png  train_batch2.jpg\tweights\n",
      "confusion_matrix.png\t\t val_batch0_labels.jpg\n",
      "\n",
      "/content/railway_hackathon_take3/merged_model_v22/weights:\n",
      "best.pt  last.pt\n"
     ]
    }
   ],
   "source": [
    "!ls -R /content/railway_hackathon_take3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2206a36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Uploaded to Drive! File ID: 1QMWopv0q0XetZ44AHWElFjnLUUzpEchu\n",
      "Go to drive.google.com, search for 'railway_hackathon_results.zip', right-click â†’ Download.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q google-auth-oauthlib  # One-time if needed\n",
    "\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "service = build('drive', 'v3')\n",
    "\n",
    "# Manual mount simulation\n",
    "mount_point = '/content/drive'\n",
    "if not os.path.exists(mount_point):\n",
    "    os.makedirs(mount_point)\n",
    "\n",
    "# Copy your files/zip to a temp spot first (if not already zipped)\n",
    "source_zip = '/content/railway_hackathon_results.zip'  # Or recreate: !zip -r {source_zip} /content/railway_hackathon_take2\n",
    "\n",
    "# Upload to Drive root (or change folder_id for a subfolder)\n",
    "file_metadata = {'name': 'railway_hackathon_results.zip'}\n",
    "media = MediaFileUpload(source_zip, resumable=True)\n",
    "uploaded_file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "\n",
    "print(f\"âœ… Uploaded to Drive! File ID: {uploaded_file.get('id')}\")\n",
    "print(\"Go to drive.google.com, search for 'railway_hackathon_results.zip', right-click â†’ Download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c7bea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
